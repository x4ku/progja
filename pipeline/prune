#!/usr/bin/env python3
import logging
import os
import sys
root_dir = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(root_dir)
import progja


logger = logging.getLogger(__name__)
progja.logging.configure_logging()


def main():
    remove_unused_sentences()


def remove_unused_sentences():
    logger.info('removing unused sentences ...')
    # find used sentences
    used_sentences = [
        sentence
        for _, path in progja.paths.load_levels().items()
        for sentence in path[path['Type'] == 'sentence']['Component']
    ]
    # prune sentences
    sentences = progja.sentences.load()
    mask = sentences['Sentence'].isin(used_sentences)
    sentences = sentences[mask]
    path = progja.data.path('sentences.csv')
    sentences.to_csv(path, index=None)
    # prune translations
    translations = progja.sentences.load_translations()
    mask = translations['Sentence'].isin(used_sentences)
    translations = translations[mask]
    path = progja.data.path('sentence-translations.csv')
    translations.to_csv(path, index=None)
    # prune compositions
    compositions = progja.sentences.load_compositions()
    compositions = [
        {'Sentence': sentence, 'Composition': [c[0] for c in components]}
        for sentence, components in compositions.items()
        if sentence in used_sentences
    ]
    progja.data.save_jsonl(compositions, 'sentence-compositions.json')
    # prune progressions
    progressions = progja.sentences.load_progressions()
    progressions = [
        {'Sentence': sentence, 'Progression': components}
        for sentence, components in progressions.items()
        if sentence in used_sentences
    ]
    progja.data.save_jsonl(progressions, 'sentence-progressions.json')
    logger.info('removed unused sentences ...')


if __name__ == '__main__':
    main()
